{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip HYRAS data to catchment extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import dask\n",
    "import contextily as ctx\n",
    "# import exactextract only if WEIGHTED_STATISTICS is True\n",
    "if True:\n",
    "    from exactextract import exact_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Define IDs and variables\n",
    "CAMELS_IDS = [1, 2, 3, 4, 5]\n",
    "HYRAS_VARIABLES = [\"Precipitation\",\n",
    "                   \"RadiationGlobal\",\n",
    "                   \"Humidity\",\n",
    "                   \"TemperatureMean\", \n",
    "                   \"TemperatureMax\", \n",
    "                   \"TemperatureMin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "INPUT_PATH = \"../input_data\"\n",
    "CATCHMENT_PATH = \"../../../catchments_harz\"\n",
    "RESULT_PATH = \"../output_data\"\n",
    "WEIGHTED_STATISTICS = True\n",
    "SAVE_NETCDF = True # save the netcdf file, can be very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping variables to datasets\n",
    "var_mapping = {\n",
    "    \"Humidity\": dict(variable_name = \"hurs\", datapath = f\"{INPUT_PATH}/hyras/Humidity/hurs_hyras_5_1951_2020_v5-0_de.nc\"),\n",
    "    \"Precipitation\": dict(variable_name = \"pr\", datapath = f\"{INPUT_PATH}/hyras/Precipitation/pr_hyras_1_1931_2020_v5-0_de.nc\"),\n",
    "    \"RadiationGlobal\": dict(variable_name = \"rsds\", datapath = f\"{INPUT_PATH}/hyras/RadiationGlobal/*.nc\"),\n",
    "    \"TemperatureMax\": dict(variable_name = \"tasmax\", datapath = f\"{INPUT_PATH}/hyras/TemperatureMax/tasmax_hyras_5_1951_2020_v5-0_de.nc\"),\n",
    "    \"TemperatureMin\": dict(variable_name = \"tasmin\", datapath = f\"{INPUT_PATH}/hyras/TemperatureMin/tasmin_hyras_5_1951_2020_v5-0_de.nc\"),\n",
    "    \"TemperatureMean\": dict(variable_name = \"tas\", datapath = f\"{INPUT_PATH}/hyras/TemperatureMean/tas_hyras_5_1951_2020_v5-0_de.nc\"),\n",
    "}\n",
    "# Mapping catchment IDs to shapefiles\n",
    "id_mapping = {\n",
    "    1: dict(shapefile = \"innerste_reservoir_catchment.shp\", catchment_id = 1),\n",
    "    2: dict(shapefile = \"oker_reservoir_catchment.shp\", catchment_id = 2),\n",
    "    3: dict(shapefile = \"ecker_reservoir_catchment.shp\", catchment_id = 3),\n",
    "    4: dict(shapefile = \"soese_reservoir_catchment.shp\", catchment_id = 4),\n",
    "    5: dict(shapefile = \"grane_reservoir_catchment.shp\", catchment_id = 5),\n",
    "}\n",
    "\n",
    "# empty list to store warnings\n",
    "warnings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camels_id in CAMELS_IDS:\n",
    "    for hyras_variable in HYRAS_VARIABLES:\n",
    "        print(f\"Processing {hyras_variable} for CAMELS_ID {camels_id}\")\n",
    "        \n",
    "        # get the variable and data_path\n",
    "        variable = var_mapping[hyras_variable][\"variable_name\"]\n",
    "        data_path = var_mapping[hyras_variable][\"datapath\"]\n",
    "        # Load data with dask for better performance with large datasets\n",
    "        ds = xr.open_mfdataset(data_path, combine=\"by_coords\", chunks=\"auto\").unify_chunks()\n",
    "\n",
    "        # Conditional slicing for Precipitation starting from 1951\n",
    "        if hyras_variable == 'Precipitation':\n",
    "            ds = ds.sel(time=slice('1951', None))\n",
    "\n",
    "        # need to set the crs (EPSG:3034)\n",
    "        ds.rio.write_crs(\"EPSG:3034\", inplace=True)\n",
    "        \n",
    "        # drop variable time_bnds, x_bnds_clipped_clipped_clipped, y_bnds and coordinate crs_HYRAS (makes problems with xarray)\n",
    "        ds = ds.drop_vars(\"time_bnds\")\n",
    "        ds = ds.drop_vars(\"x_bnds\")\n",
    "        ds = ds.drop_vars(\"y_bnds\")\n",
    "        \n",
    "        # set the spatial dimensions\n",
    "        ds.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n",
    "\n",
    "        catchment_info = id_mapping[camels_id]\n",
    "        shapefile_path = os.path.join(CATCHMENT_PATH, catchment_info[\"shapefile\"])\n",
    "        catchment = gpd.read_file(shapefile_path)\n",
    "        # Transform crs to EPSG:3034 to be in the same crs as the hyras data\n",
    "        catchment = catchment.to_crs(epsg=3034)\n",
    "\n",
    "        # make output folder if it does not exist\n",
    "        os.makedirs(f\"{RESULT_PATH}/{camels_id}/data\", exist_ok=True)\n",
    "        # Save catchment as geojson to the output folder depending on the CAMELS_ID\n",
    "        catchment.to_file(f\"{RESULT_PATH}/{camels_id}/data/catchment.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "        # Do the Clip\n",
    "        # Clip the data to the catchment shape, all_touched=True to get all pixels that are at least partially in the catchment\n",
    "        ds_clipped = ds.rio.clip(catchment.geometry, all_touched=True)\n",
    "\n",
    "        # Load the data into memory, this yielded the fastest computation times\n",
    "        ds_clipped = ds_clipped.load()\n",
    "\n",
    "        # Plotting spatial data\n",
    "        # plot ds_clipped together with gdf_polygon\n",
    "        fig_spatial, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "        # plot ds_clipped on top\n",
    "        ds_clipped[variable].isel(time=0).plot(alpha=1, ax=ax, cmap=\"viridis\")\n",
    "\n",
    "        # plot catchment first, big red border, no fill\n",
    "        catchment.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=3)\n",
    "\n",
    "        # add basemap but this needs an in internet connection and sometimes takes a while\n",
    "        try:\n",
    "            ctx.add_basemap(ax, crs=ds_clipped.rio.crs.to_string(), source=ctx.providers.OpenTopoMap)\n",
    "        except Exception as e:\n",
    "            print(f\"Basemap loading not succesfull: {e}\")\n",
    "            warnings.append(f\"Basemap loading not succesfull: {e}\")\n",
    "\n",
    "        # Increase x and y limits\n",
    "        xmin, xmax = ax.get_xlim()\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ax.set_xlim(xmin - 0.2*(xmax-xmin), xmax + 0.2*(xmax-xmin))\n",
    "        ax.set_ylim(ymin - 0.2*(ymax-ymin), ymax + 0.2*(ymax-ymin))\n",
    "\n",
    "        # Add a title\n",
    "        ax.set_title(f\"{hyras_variable} clipped to catchment {camels_id}\")\n",
    "\n",
    "        # Aggregate to timeseries and calculate statistics\n",
    "        # Remove the grid_mapping key from the variable's attributes (problems with xarray)\n",
    "        ds_clipped[variable].attrs.pop(\"grid_mapping\", None)\n",
    "\n",
    "        # drop variable crs_HYRAS (problems with xarray)\n",
    "        ds_clipped = ds_clipped.drop_vars(\"crs_HYRAS\")\n",
    "\n",
    "        # if WEIGHTED_STATISTICS is True, use exactextract to calculate weighted statistics\n",
    "        if WEIGHTED_STATISTICS:\n",
    "            # list of statistics to calculate\n",
    "            statistics = [\"mean\", \"min\", \"median\", \"max\", \"stdev\"]\n",
    "\n",
    "            # calculate the weighted statistics\n",
    "            df_weighted = exact_extract(ds_clipped[variable], catchment, statistics, output=\"pandas\")\n",
    "\n",
    "            # process df_weighted to get it to the right format\n",
    "            df = df_weighted.T\n",
    "\n",
    "            # get the time index from the xarray dataset\n",
    "            time_index = ds_clipped.time.values\n",
    "\n",
    "            # create a list of dataframes, each dataframe contains the timeseries for one statistic\n",
    "            sliced_dfs = [df.iloc[i:i+len(time_index)] for i in range(0, len(df), len(time_index))]\n",
    "\n",
    "            # set the index to the time values and rename the columns\n",
    "            for i, df in enumerate(sliced_dfs):\n",
    "                df.index = time_index\n",
    "                df.columns = [f\"{variable}_{statistics[i]}\"]\n",
    "\n",
    "            # concatenate the dataframes\n",
    "            df_timeseries = pd.concat(sliced_dfs, axis=1)\n",
    "\n",
    "        # Plotting timeseries \n",
    "        fig_timeseries = plt.figure(figsize=(10, 7))\n",
    "\n",
    "        # Define the height ratios for the subplots\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[2, 1]) \n",
    "\n",
    "        # Plot all columns except 'hurs_std' in the first subplot\n",
    "        ax0 = plt.subplot(gs[0])\n",
    "        lines1 = df_timeseries.drop(columns=[f\"{variable}_stdev\"]).groupby(pd.Grouper(freq='Y')).mean().plot(ax=ax0, lw=2, legend=False)\n",
    "        ax0.set_title(f\"{hyras_variable} yearly mean timeseries for catchment {camels_id}\\n\")\n",
    "        ax0.xaxis.set_visible(False)  # Remove x-axis\n",
    "\n",
    "        # Plot 'hurs_std' in the second subplot\n",
    "        ax1 = plt.subplot(gs[1])\n",
    "        lines2 = df_timeseries[f\"{variable}_stdev\"].groupby(pd.Grouper(freq='Y')).mean().plot(ax=ax1, lw=2, color='orange', legend=False)\n",
    "        \n",
    "        # Create a shared legend\n",
    "        lines = lines1.get_lines() + lines2.get_lines()\n",
    "        labels = [line.get_label() for line in lines]\n",
    "        \n",
    "        # Move the legend outside of the plot to the bottom\n",
    "        fig_timeseries.legend(lines, labels, loc='upper center', bbox_to_anchor=(0.5, 0), ncol=len(lines))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save results\n",
    "        \n",
    "        # Make output directory if it does not exist\n",
    "        os.makedirs(f\"{RESULT_PATH}/{camels_id}/plots\", exist_ok=True)\n",
    "        os.makedirs(f\"{RESULT_PATH}/{camels_id}/data\", exist_ok=True)\n",
    "        \n",
    "        # Save figures\n",
    "        fig_spatial.savefig(f\"{RESULT_PATH}/{camels_id}/plots/{hyras_variable}_catchment_clipped.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        fig_timeseries.savefig(f\"{RESULT_PATH}/{camels_id}/plots/{hyras_variable}_timeseries.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        \n",
    "        # Save timeseries data\n",
    "        df_timeseries.to_csv(f\"{RESULT_PATH}/{camels_id}/data/{camels_id}_{hyras_variable}.csv\")\n",
    "        \n",
    "        # Save clipped data\n",
    "        if SAVE_NETCDF:\n",
    "            ds_clipped.to_netcdf(f\"{RESULT_PATH}/{camels_id}/data/{camels_id}_{hyras_variable}_clipped.nc\")\n",
    "        # close xarray datasets\n",
    "        ds.close()\n",
    "        ds_clipped.close()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
